{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6xMLOFP4Xr9",
        "outputId": "9add01e2-ba5a-4afb-999a-bc961d044f97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.5.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.1)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.18.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2nRw070zCTr"
      },
      "outputs": [],
      "source": [
        "cache = {}\n",
        "Triplets_collection = []\n",
        "\n",
        "def get_text(response):\n",
        "    candidates = response.candidates\n",
        "\n",
        "    if candidates:\n",
        "        content_parts = candidates[0].content.parts\n",
        "        texts = [part.text for part in content_parts if part.text]  # Ensure that part.text is not None or empty\n",
        "\n",
        "        if texts:\n",
        "            json_text = texts[0]\n",
        "            # Check if json_text starts and ends with ```json which indicates it's a JSON block\n",
        "            if json_text.startswith(\"```json\") and json_text.endswith(\"```\"):\n",
        "                json_text = json_text[7:-3].strip()  # Strip the markdown code block indicators\n",
        "                try:\n",
        "                    data = json.loads(json_text)\n",
        "                    return data\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(\"Failed to decode JSON:\", e)  # Print error message if JSON is invalid\n",
        "                    return None  # Return None or handle as needed\n",
        "            else:\n",
        "                print(\"No JSON block found in the text.\")\n",
        "                return None  # Return None if there is no JSON block\n",
        "        else:\n",
        "            print(\"No text available to decode.\")\n",
        "            return None  # Return None if there are no text parts\n",
        "\n",
        "    print(\"No candidates available.\")\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlOiuMT-4a95"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "import time\n",
        "key = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=key)\n",
        "\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 64,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBS_izsEh1j2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"harry_potter_books.csv\")\n",
        "\n",
        "def list_chapters(book):\n",
        "    return df[df['book'] == book]['chapter'].unique()\n",
        "\n",
        "def get_chapter_text(book, chapter, max_length=1000):\n",
        "\n",
        "    chapter_data = df[(df['book'] == book) & (df['chapter'] == chapter)]\n",
        "    chapter_text = ' '.join(chapter_data['text'])\n",
        "    chunks = []\n",
        "    while len(chapter_text) > max_length:\n",
        "        cut_off = chapter_text.rfind(' ', 0, max_length)\n",
        "        if cut_off == -1:\n",
        "            cut_off = max_length\n",
        "        chunks.append(chapter_text[:cut_off])\n",
        "        chapter_text = chapter_text[cut_off:].lstrip()\n",
        "\n",
        "    if chapter_text:\n",
        "        chunks.append(chapter_text)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKXC_MVaKMTb"
      },
      "outputs": [],
      "source": [
        "def send_request_with_retries(chat_sessionC, request, max_retries=4, delay=2):\n",
        "    retry_count = 0\n",
        "    while retry_count < max_retries:\n",
        "        try:\n",
        "            # Attempt to send the request\n",
        "            response = chat_sessionC.send_message(request)\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            # Print error message and retry after delay\n",
        "            print(f\"Error on attempt {retry_count + 1}: {e}\")\n",
        "            time.sleep(delay)\n",
        "            retry_count += 1\n",
        "    # Return None if all retries fail\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUl2ocl8LisD"
      },
      "outputs": [],
      "source": [
        "modelE = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  generation_config=generation_config,\n",
        "  system_instruction = \"You are an expert in Knowledge Graph. You will try your best to extract the entities and relationships from the text. Do not produce any triplets that is not in the text.\"\n",
        ")\n",
        "\n",
        "chat_sessionE = modelE.start_chat(\n",
        "  history=[\n",
        "  ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjR6X0CaMoMM"
      },
      "outputs": [],
      "source": [
        "modelE = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  generation_config=generation_config,\n",
        "  system_instruction = \"You are an expert in Knowledge Graph. You will try your best to extract the entities and relationships from the text. Do not produce any triplets that is not in the text. And the triplets should two entities' interaction.\"\n",
        ")\n",
        "\n",
        "chat_sessionE = modelE.start_chat(\n",
        "  history=[\n",
        "  ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0X2UMp5nLisD"
      },
      "outputs": [],
      "source": [
        "def Extraction(text):\n",
        "  request = f\"\"\"\n",
        "  Given a piece of text, extract relational triplets in the form of {{head: Subject, type: Relation, tail: Object}} from it. Here are some examples.\n",
        "  ### Example ###\n",
        "  Text: The 17068.8 millimeter long ALCO RS-3 has a diesel-electric transmission.\n",
        "  Triplets: {{head: \"ALCO RS-3\", type: \"powerType\", tail: \"Diesel-electric transmission\"}}, {{head: \"ALCO RS-3\", type: \"length\", tail: \"17068.8 millimeters\"}}\n",
        "\n",
        "  Now extract triplets from the following text:\n",
        "  {text}\n",
        "  \"\"\"\n",
        "  response = chat_sessionE.send_message(request)\n",
        "  return get_text(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qikDjavQLisD"
      },
      "outputs": [],
      "source": [
        "modelD = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  generation_config=generation_config,\n",
        "  system_instruction = \"You are an expert in giving the definition of entities and relationships from the text.\"\n",
        ")\n",
        "\n",
        "chat_sessionD = modelD.start_chat(\n",
        "  history=[\n",
        "  ]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkYkR5khLisE"
      },
      "outputs": [],
      "source": [
        "def Definition(text,free_extract):\n",
        "  request = f\"\"\"\n",
        "  Given a piece of text and a list of relational triplets extracted from it, write a definition for each relationship present.\n",
        "  ### Example ###\n",
        "  Text: The 17068.8 millimeter long ALCO RS-3 has a diesel-electric transmission.\n",
        "  Triplets:{{\"head\": \"ALCO RS-3\", \"type\": \"powerType\", \"tail\": \"Diesel-electric transmission\"}}, {{\"head\": \"ALCO RS-3\", \"type\": \"length\", \"tail\": \"17068.8 millimeters\"}}\n",
        "  Definition: {{\"powerType\": \"The subject entity uses the type of power or energy source specified by the object entity\"}},{{\"length\": \"The measurement or extent of something from end to end; the greater of two or the greatest of three dimensions of an object.\"}}\n",
        "\n",
        "  Now extract triplets from the following text and triplets:\n",
        "  {text}\n",
        "  {free_extract}\n",
        "  \"\"\"\n",
        "\n",
        "  response = chat_sessionD.send_message(request)\n",
        "  return get_text(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2xAKs9nKIRJ"
      },
      "outputs": [],
      "source": [
        "modelC = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  generation_config=generation_config,\n",
        "  system_instruction = \"You are an expert in finding the most relevant words from file. Only if the two words are similar and you are confident about or you seem this word is a new category.\"\n",
        ")\n",
        "\n",
        "chat_sessionC = modelC.start_chat(\n",
        "  history=[\n",
        "  ]\n",
        ")\n",
        "\n",
        "requestC = f\"\"\"\n",
        "Given a piece of text, triplets, and their definitions, check if any synonym pairs in the definition have a similar meaning to entries in the file \"cache\". If a synonym is found, replace the corresponding word in the triplets. Respond with \"no\" if no synonymous word can be found in the cache. You just answer \"no\" if there are not corresponding words, or answer only the replaced triplets. I do not need any extract information.\n",
        "\n",
        "Text: {{text}}\n",
        "Triplets: {{triplets}}\n",
        "Definition: {{definition}}\n",
        "Cache: {{cache}}\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB-mV-dKKczJ"
      },
      "outputs": [],
      "source": [
        "def Canonicalization(text,free_extract,definition):\n",
        "  for triplets in free_extract:\n",
        "\n",
        "    print('process request')\n",
        "    request = requestC.format(text=text, triplets=triplets, definition=definition, cache=cache)\n",
        "    print('finish process request')\n",
        "    response_text = send_request_with_retries(chat_sessionC, request)\n",
        "    print(response_text)\n",
        "    if response_text is not None:\n",
        "      if \"no\" in response_text:\n",
        "        cache[triplets['type']] = definition[triplets['type']]\n",
        "        Triplets_collection.append(triplets)\n",
        "      else:\n",
        "        Triplets_collection.append(triplets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdFeIJslL5E-"
      },
      "outputs": [],
      "source": [
        "def mainfunction(text):\n",
        "  print(text)\n",
        "  free_extract = Extraction(text)\n",
        "  if not free_extract:\n",
        "    print('no extract from the chunk')\n",
        "    return\n",
        "  print('free_Extract:', free_extract)\n",
        "  definition = Definition(text,free_extract)\n",
        "  if not definition:\n",
        "    print('no definition from the chunk')\n",
        "    return\n",
        "  print('definition:',definition)\n",
        "  Canonicalization(text,free_extract,definition)\n",
        "  print('Triplets_collection:' ,Triplets_collection,'/nCache:',cache)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "TVd3Bgs6x0pC",
        "outputId": "d6852c7b-4460-4f73-8cd3-2090eba51a0b"
      },
      "outputs": [],
      "source": [
        "book_name = \"Book 1: Philosopher's Stone\"\n",
        "list_chatper = list_chapters(book_name)\n",
        "for chapter in list_chatper:\n",
        "  chunks_of_chapter = get_chapter_text(book_name, chapter, 3000)\n",
        "  for chunk in chunks_of_chapter:\n",
        "    mainfunction(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5WZ5QtZ6qqm"
      },
      "outputs": [],
      "source": [
        "with open('Triplets_collection.json', 'w') as json_file:\n",
        "    json.dump(Triplets_collection, json_file)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "kabfWxCTZnTf",
        "ekGnutl3ZzTz",
        "08RukxO23PsX",
        "0r6Ko6xjBwT0",
        "XMs4hbOS8E5e",
        "zj6Bp8IaaSPJ",
        "LxBSnpS1P2sX",
        "f3eGbhHtoeEA"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
